{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This script uses a chromedriver (with its head) to scrape links to articles. \n",
    "# The script is therefore very OS dependent and may not work in other environments in its current state.\n",
    "\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import json\n",
    "\n",
    "# Path for storing data and urls\n",
    "data_path = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and starting chrome webdriver\n",
    "driver = webdriver.Chrome(executable_path = 'C:\\\\chromedriver\\\\chromedriver.exe')\n",
    "\n",
    "driver.get('https://www.horesta.dk/nyheder/')\n",
    "time.sleep(3)\n",
    "\n",
    "# Coords for reaching p.btn-load-more button\n",
    "x_coord = 0\n",
    "y_coord = 2400\n",
    "\n",
    "# Scrolls through posts until p.btn-load-more button no longer shows up (no more posts)\n",
    "while True:\n",
    "    coordinates = {'x': x_coord, 'y': y_coord}\n",
    "    driver.execute_script('window.scrollTo({}, {});'.format(coordinates['x'], coordinates['y']))\n",
    "    try:\n",
    "        driver.find_element_by_css_selector(\"p.btn-load-more\").click()\n",
    "        y_coord = y_coord + 2400\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "\n",
    "# Store the entire loaded page source as one html document        \n",
    "pageSource = driver.page_source\n",
    "\n",
    "# Quit the chome driver\n",
    "driver.quit()\n",
    "\n",
    "# Convert pagesource to soup object\n",
    "pagesoup = bs(pageSource)\n",
    "\n",
    "# Extract links to posts\n",
    "links = [s.find('a')['href'] for s in pagesoup.find_all('div', class_ = 'post-item')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store links as txt\n",
    "with open(os.path.join(data_path,'horesta_urls.txt'), 'w', encoding = 'utf-8') as f:\n",
    "    for link in links:\n",
    "        f.write(link + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions\n",
    "\n",
    "def get_article_links(soup):\n",
    "    \"\"\"\n",
    "    Retrieves all href attributes from a tags in a soup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for s in soup.find_all('a'):\n",
    "        try:\n",
    "            links.append(s['href'])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return(links)\n",
    "\n",
    "def get_article_tags(soup):\n",
    "    \"\"\"\n",
    "    Retrieves the post tags as set by Horesta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        article_tags = soup.find('ul', class_='tag-list').get_text().strip().split('\\n')\n",
    "    except:\n",
    "        article_tags = []\n",
    "        \n",
    "    return(article_tags)\n",
    "\n",
    "def get_article_info(url):\n",
    "    \"\"\"\n",
    "    Retrieves article info: url, title, tags, links in article, publish date, article text and source code.\n",
    "    Also stores dummy variable 'accessed' for whether or not article was accessed as well as date of access.\n",
    "    Returns as a dictionary with keys: url, accessed, title, tags, links, publish_date, access_date, text, html\n",
    "    \"\"\"\n",
    "    article_dict = {}\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        article_dict['url'] = url\n",
    "        article_dict['accessed'] = 0\n",
    "        article_dict['title'] = \"\"\n",
    "        article_dict['tags'] = \"\"\n",
    "        article_dict['links'] = \"\"\n",
    "        article_dict['publish_date'] = \"\"\n",
    "        article_dict['access_date'] = str(dt.now().date())\n",
    "        article_dict['text'] = \"\"\n",
    "        article_dict['html'] = \"\"\n",
    "    else:\n",
    "        soup = bs(response.content)\n",
    "        article_soup = soup.find('article', class_='article-main')\n",
    "        \n",
    "        article_dict['url'] = url\n",
    "        article_dict['accessed'] = 1\n",
    "        article_dict['title'] = soup.find('h1', class_='margin-top-bottom-0').get_text(strip = True)\n",
    "        article_dict['tags'] = get_article_tags(soup)\n",
    "        article_dict['links'] = get_article_links(article_soup)\n",
    "        article_dict['publish_date'] = soup.find('div', id = 'divDate').find('span').next_sibling.get_text()\n",
    "        article_dict['access_date'] = str(dt.now().date())\n",
    "        article_dict['text'] = article_soup.get_text()\n",
    "        article_dict['html'] = str(soup)\n",
    "        \n",
    "    return(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of articles downloaded\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-9432208ea5c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# saving as json list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'horesta_posts.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieving articles based on list of links\n",
    "articles = list()\n",
    "\n",
    "for c, link in enumerate(links, start = 1):\n",
    "    link = \"https://horesta.dk\" + link\n",
    "    art_dict = get_article_info(link)\n",
    "    articles.append(art_dict)\n",
    "      \n",
    "    print(\"{:.2f}% of articles downloaded\".format(100.0 * c/len(links)), end = '\\r')\n",
    "    \n",
    "    sleep_time = random.uniform(0.3, 0.9)\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving articles as json list\n",
    "with open( os.path.join(data_path,'horesta_posts.json'), 'w', encoding = 'utf-8') as f:\n",
    "    json.dump(articles, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
